import requests
from bs4 import BeautifulSoup
import pandas as pd

# URL target
url = 'https://news.detik.com/berita'

# Request ke website
response = requests.get(url)

# Parsing HTML menggunakan BeautifulSoup
soup = BeautifulSoup(response.content, 'html.parser')

# Mendapatkan semua link artikel
links = []
for article in soup.find_all('article'):
    link = article.find('a')
    if link is not None and 'detik.com' in link['href']:
        links.append(link['href'])

# Membuat list kosong untuk menyimpan data artikel
data = []

# Mendapatkan konten dari setiap link artikel dan menyimpan dalam list data
for link in links:
    article_response = requests.get(link)
    article_soup = BeautifulSoup(article_response.content, 'html.parser')
    title = article_soup.find('h1', class_='detail__title')
    content = article_soup.find('div', class_='detail__body-text itp_bodycontent')
    author = article_soup.find('div', class_='detail__author')
    date = article_soup.find('div', class_='detail__date')
    if title is not None and content is not None and author is not None and date is not None:
        # Menghapus konten yang mengandung tulisan 'ADVERTISEMENT' dan 'SCROLL TO RESUME CONTENT'
        content_text = content.text.replace('\n', '').replace('ADVERTISEMENT', '').replace('SCROLL TO RESUME CONTENT', '').strip()
        data.append([title.text.replace('\n', '').strip(), content_text, author.text.strip(), date.text.strip(), link])

# Membuat dataframe dari list data
df = pd.DataFrame(data, columns=['Judul', 'Isi Artikel', 'Penulis', 'Tanggal Terbit', 'Link Berita'])

# Menghapus kolom yang duplikat
df = df.drop_duplicates(subset='Link Berita')

# Mengurutkan dataframe berdasarkan tanggal terbit
df = df.sort_values(by=['Tanggal Terbit'], ascending=True)

# Menampilkan dataframe
df.head()
